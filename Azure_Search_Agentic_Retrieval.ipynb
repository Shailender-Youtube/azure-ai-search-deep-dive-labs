{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1784274",
   "metadata": {},
   "source": [
    "# Azure AI Search: Agentic Retrieval "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473bd8f7",
   "metadata": {},
   "source": [
    "## Step 1: Install Required Packages\n",
    "Install Azure Search Documents SDK (preview version) with agentic retrieval support, authentication, and HTTP client libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16c5255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (preview SDK for agentic retrieval)\n",
    "import sys\n",
    "import subprocess\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"azure-search-documents\", \"--pre\", \"--force-reinstall\", \"azure-identity\", \"requests\", \"--quiet\"])\n",
    "print(\"‚úì All packages installed (preview SDK with agentic retrieval support)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eee67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries (SDK approach from official quickstart)\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "\n",
    "# Agentic retrieval SDK classes\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexKnowledgeSource, \n",
    "    SearchIndexKnowledgeSourceParameters,\n",
    "    SearchIndexFieldReference,\n",
    "    KnowledgeBase,\n",
    "    KnowledgeBaseAzureOpenAIModel,\n",
    "    KnowledgeSourceReference,\n",
    "    AzureOpenAIVectorizerParameters,\n",
    "    KnowledgeRetrievalOutputMode,\n",
    "    KnowledgeRetrievalLowReasoningEffort\n",
    ")\n",
    "from azure.search.documents.knowledgebases import KnowledgeBaseRetrievalClient\n",
    "from azure.search.documents.knowledgebases.models import (\n",
    "    KnowledgeBaseRetrievalRequest,\n",
    "    KnowledgeBaseMessage,\n",
    "    KnowledgeBaseMessageTextContent,\n",
    "    SearchIndexKnowledgeSourceParams\n",
    ")\n",
    "import requests\n",
    "import json\n",
    "\n",
    "print(\"‚úì All libraries imported (SDK with agentic retrieval support)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faa0bf9",
   "metadata": {},
   "source": [
    "## Step 2: Configuration and Authentication (Managed Identity)\n",
    "Set up connections to Azure AI Search, Azure OpenAI Foundry, and configure the agentic retrieval components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f24c73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - Microsoft Foundry + Azure AI Search\n",
    "search_endpoint = \"https://xxxxxxxxxxxxxxx.search.windows.net\"\n",
    "\n",
    "# Microsoft Foundry endpoint (where models are deployed)\n",
    "aoai_endpoint = \"https://xxxxxxxxxxxxxxx.cognitiveservices.azure.com\"\n",
    "\n",
    "# Use existing semantic index (agentic retrieval requires semantic configuration)\n",
    "index_name = \"hotels-semantic-index\"\n",
    "\n",
    "# Agentic retrieval objects\n",
    "knowledge_source_name = \"hotels-knowledge-source\"\n",
    "knowledge_base_name = \"hotels-knowledge-base\"\n",
    "\n",
    "# Azure OpenAI models deployed in Foundry\n",
    "aoai_embedding_model = \"text-embedding-ada-002\"\n",
    "aoai_embedding_deployment = \"text-embedding-ada-002\"\n",
    "aoai_gpt_model = \"gpt-5-mini\"\n",
    "aoai_gpt_deployment = \"gpt-5-mini\"\n",
    "\n",
    "# Managed Identity\n",
    "credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(credential, \"https://search.azure.com/.default\")\n",
    "\n",
    "print(f\"‚úì Azure Search: {search_endpoint}\")\n",
    "print(f\"‚úì Foundry: {aoai_endpoint}\")\n",
    "print(f\"‚úì Source Index: {index_name}\")\n",
    "print(f\"‚úì Knowledge Source: {knowledge_source_name}\")\n",
    "print(f\"‚úì Knowledge Base: {knowledge_base_name}\")\n",
    "print(f\"‚úì LLM: {aoai_gpt_deployment}\")\n",
    "print(f\"‚úì Embeddings: {aoai_embedding_deployment}\")\n",
    "print(f\"‚úì Authentication: Managed Identity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d03ebd",
   "metadata": {},
   "source": [
    "## Step 3: Verify Existing Hotels Index\n",
    "Confirm the hotels-semantic-index exists and contains 50 hotels ready for agentic retrieval queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c7c641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify hotels-vector-index exists and has data\n",
    "search_client = SearchClient(endpoint=search_endpoint, index_name=index_name, credential=credential)\n",
    "result = search_client.search(search_text=\"*\", include_total_count=True, top=3, select=[\"HotelName\", \"Category\", \"Rating\"])\n",
    "\n",
    "count = result.get_count()\n",
    "print(f\"‚úì Index '{index_name}' contains {count} hotels\\n\")\n",
    "\n",
    "print(\"Sample hotels:\")\n",
    "for i, doc in enumerate(result, 1):\n",
    "    print(f\"{i}. {doc['HotelName']} ({doc.get('Rating', 0)}‚òÖ, {doc.get('Category', 'N/A')})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdfa3c2",
   "metadata": {},
   "source": [
    "## Step 4: Create Knowledge Source\n",
    "Define a knowledge source that references the hotels search index and specifies which fields to use for retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ab3815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create knowledge source using SDK\n",
    "ks = SearchIndexKnowledgeSource(\n",
    "    name=knowledge_source_name,\n",
    "    description=\"Knowledge source for 50 real hotels with descriptions, categories, and ratings\",\n",
    "    search_index_parameters=SearchIndexKnowledgeSourceParameters(\n",
    "        search_index_name=index_name,\n",
    "        source_data_fields=[\n",
    "            SearchIndexFieldReference(name=\"HotelId\"),\n",
    "            SearchIndexFieldReference(name=\"HotelName\"),\n",
    "            SearchIndexFieldReference(name=\"Category\"),\n",
    "            SearchIndexFieldReference(name=\"Rating\")\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=search_endpoint, credential=credential)\n",
    "index_client.create_or_update_knowledge_source(knowledge_source=ks)\n",
    "\n",
    "print(f\"‚úì Knowledge source '{knowledge_source_name}' created or updated\")\n",
    "print(f\"  - References index: {index_name}\")\n",
    "print(f\"  - Source data fields: HotelId, HotelName, Category, Rating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128e7dc4",
   "metadata": {},
   "source": [
    "## Step 5: Create Knowledge Base with Answer Synthesis\n",
    "Define the knowledge base with LLM configuration (gpt-5-mini) for intelligent query orchestration and conversational answer generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a191547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create knowledge base using SDK (matching official quickstart)\n",
    "aoai_params = AzureOpenAIVectorizerParameters(\n",
    "    resource_url=aoai_endpoint,\n",
    "    deployment_name=aoai_gpt_deployment,\n",
    "    model_name=aoai_gpt_model,\n",
    ")\n",
    "\n",
    "knowledge_base = KnowledgeBase(\n",
    "    name=knowledge_base_name,\n",
    "    models=[KnowledgeBaseAzureOpenAIModel(azure_open_ai_parameters=aoai_params)],\n",
    "    knowledge_sources=[KnowledgeSourceReference(name=knowledge_source_name)],\n",
    "    output_mode=KnowledgeRetrievalOutputMode.ANSWER_SYNTHESIS,\n",
    "    answer_instructions=\"You are a knowledgeable hotel concierge. Provide helpful, conversational hotel recommendations based on retrieved data. Always cite sources using [ref_id:X] format. Be specific about amenities, features, and ratings.\"\n",
    ")\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=search_endpoint, credential=credential)\n",
    "index_client.create_or_update_knowledge_base(knowledge_base)\n",
    "\n",
    "print(f\"‚úì Knowledge base '{knowledge_base_name}' created or updated\")\n",
    "print(f\"  - LLM: {aoai_gpt_deployment} (via {aoai_endpoint})\")\n",
    "print(f\"  - Mode: Answer Synthesis (conversational responses)\")\n",
    "print(f\"  - Sources: {knowledge_source_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593a9641",
   "metadata": {},
   "source": [
    "---\n",
    "# Agentic Retrieval in Action\n",
    "\n",
    "Now we'll demonstrate how the LLM agent intelligently handles complex queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e389fb",
   "metadata": {},
   "source": [
    "## Query 1: Complex Multi-Part Request (Family Vacation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776eced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up messages and run first query\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a knowledgeable hotel concierge helping travelers find the perfect hotel. If you don't have the answer, respond with 'I don't know'.\"}\n",
    "]\n",
    "\n",
    "query_1 = \"\"\"\n",
    "I'm planning a family vacation for summer. We need a hotel that:\n",
    "- Is suitable for children and families\n",
    "- Has outdoor activities or is near nature\n",
    "- Has good amenities (WiFi, breakfast, etc.)\n",
    "- Has high ratings (at least 3.5 stars)\n",
    "What would you recommend and why?\n",
    "\"\"\"\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": query_1})\n",
    "\n",
    "# Use SDK KnowledgeBaseRetrievalClient\n",
    "agent_client = KnowledgeBaseRetrievalClient(\n",
    "    endpoint=search_endpoint, \n",
    "    knowledge_base_name=knowledge_base_name, \n",
    "    credential=credential\n",
    ")\n",
    "\n",
    "req = KnowledgeBaseRetrievalRequest(\n",
    "    messages=[\n",
    "        KnowledgeBaseMessage(\n",
    "            role=m[\"role\"],\n",
    "            content=[KnowledgeBaseMessageTextContent(text=m[\"content\"])]\n",
    "        ) for m in messages if m[\"role\"] != \"system\"\n",
    "    ],\n",
    "    knowledge_source_params=[\n",
    "        SearchIndexKnowledgeSourceParams(\n",
    "            knowledge_source_name=knowledge_source_name,\n",
    "            include_references=True,\n",
    "            include_reference_source_data=True,\n",
    "            always_query_source=True\n",
    "        )\n",
    "    ],\n",
    "    include_activity=True,\n",
    "    retrieval_reasoning_effort=KnowledgeRetrievalLowReasoningEffort\n",
    ")\n",
    "\n",
    "result = agent_client.retrieve(retrieval_request=req)\n",
    "print(f\"‚úì Retrieved content from '{knowledge_base_name}' successfully.\\n\")\n",
    "\n",
    "# Display response\n",
    "print(f\"Query: {query_1.strip()}\\n\")\n",
    "print(f\"{'='*80}\")\n",
    "print(\"AGENTIC RETRIEVAL RESPONSE:\\n\")\n",
    "\n",
    "response_parts = []\n",
    "for resp in result.response:\n",
    "    for content in resp.content:\n",
    "        response_parts.append(content.text)\n",
    "response_content = \"\\n\\n\".join(response_parts) if response_parts else \"No response\"\n",
    "print(response_content)\n",
    "\n",
    "messages.append({\"role\": \"assistant\", \"content\": response_content})\n",
    "\n",
    "# Show activity log (query decomposition)\n",
    "if result.activity:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"ACTIVITY LOG (Query Decomposition):\\n\")\n",
    "    activity_data = [a.as_dict() for a in result.activity]\n",
    "    for activity in activity_data:\n",
    "        activity_type = activity.get('type', 'unknown')\n",
    "        if activity_type == 'modelQueryPlanning':\n",
    "            print(f\"üß† Query Planning by LLM:\")\n",
    "            print(f\"   Input tokens: {activity.get('input_tokens', 0)}\")\n",
    "            print(f\"   Output tokens: {activity.get('output_tokens', 0)}\")\n",
    "            print(f\"   Time: {activity.get('elapsed_ms', 0)}ms\\n\")\n",
    "        elif activity_type == 'searchIndex':\n",
    "            args = activity.get('search_index_arguments', {})\n",
    "            print(f\"üîç Subquery {activity.get('id', '?')}: {args.get('search', 'N/A')}\")\n",
    "            print(f\"   Results: {activity.get('count', 0)} documents\")\n",
    "            print(f\"   Time: {activity.get('elapsed_ms', 0)}ms\\n\")\n",
    "        elif activity_type == 'agenticReasoning':\n",
    "            print(f\"ü§î Agentic Reasoning:\")\n",
    "            print(f\"   Reasoning tokens: {activity.get('reasoning_tokens', 0)}\\n\")\n",
    "        elif activity_type == 'modelAnswerSynthesis':\n",
    "            print(f\"üí¨ Answer Synthesis by LLM:\")\n",
    "            print(f\"   Input tokens: {activity.get('input_tokens', 0)}\")\n",
    "            print(f\"   Output tokens: {activity.get('output_tokens', 0)}\")\n",
    "            print(f\"   Time: {activity.get('elapsed_ms', 0)}ms\\n\")\n",
    "\n",
    "# Show references\n",
    "if result.references:\n",
    "    print(f\"{'='*80}\")\n",
    "    print(\"REFERENCED HOTELS:\\n\")\n",
    "    for i, ref in enumerate(result.references[:5], 1):\n",
    "        ref_dict = ref.as_dict()\n",
    "        source_data = ref_dict.get('source_data', {})\n",
    "        print(f\"{i}. {source_data.get('HotelName', 'N/A')}\")\n",
    "        print(f\"   Category: {source_data.get('Category', 'N/A')} | Rating: {source_data.get('Rating', 0)}‚òÖ\")\n",
    "        print(f\"   Reranker Score: {ref_dict.get('reranker_score', 0):.4f}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0809c4",
   "metadata": {},
   "source": [
    "## Query 2: Follow-Up Question (Maintains Context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ae4ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow-up question - agent remembers previous context\n",
    "query_2 = \"Which of those hotels has the best rating and is closest to water or a lake?\"\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": query_2})\n",
    "\n",
    "req = KnowledgeBaseRetrievalRequest(\n",
    "    messages=[\n",
    "        KnowledgeBaseMessage(\n",
    "            role=m[\"role\"],\n",
    "            content=[KnowledgeBaseMessageTextContent(text=m[\"content\"])]\n",
    "        ) for m in messages if m[\"role\"] != \"system\"\n",
    "    ],\n",
    "    knowledge_source_params=[\n",
    "        SearchIndexKnowledgeSourceParams(\n",
    "            knowledge_source_name=knowledge_source_name,\n",
    "            include_references=True,\n",
    "            include_reference_source_data=True,\n",
    "            always_query_source=True\n",
    "        )\n",
    "    ],\n",
    "    include_activity=True,\n",
    "    retrieval_reasoning_effort=KnowledgeRetrievalLowReasoningEffort\n",
    ")\n",
    "\n",
    "result = agent_client.retrieve(retrieval_request=req)\n",
    "print(f\"‚úì Retrieved content from '{knowledge_base_name}' successfully.\\n\")\n",
    "\n",
    "print(f\"Follow-Up Query: {query_2}\")\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"AGENTIC RETRIEVAL RESPONSE:\\n\")\n",
    "\n",
    "response_parts = []\n",
    "for resp in result.response:\n",
    "    for content in resp.content:\n",
    "        response_parts.append(content.text)\n",
    "response_content = \"\\n\\n\".join(response_parts) if response_parts else \"No response\"\n",
    "print(response_content)\n",
    "\n",
    "messages.append({\"role\": \"assistant\", \"content\": response_content})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb15b20",
   "metadata": {},
   "source": [
    "## Query 3: Business + Luxury Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151ba1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New conversation - Business + Luxury query\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a knowledgeable hotel concierge. If you don't have the answer, respond with 'I don't know'.\"}\n",
    "]\n",
    "\n",
    "query_3 = \"\"\"\n",
    "I'm looking for a luxury hotel suitable for a business conference. \n",
    "It needs to be in a city center with modern facilities. \n",
    "I also want a spa for relaxation after meetings. \n",
    "What are my best options with ratings above 4 stars?\n",
    "\"\"\"\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": query_3})\n",
    "\n",
    "req = KnowledgeBaseRetrievalRequest(\n",
    "    messages=[\n",
    "        KnowledgeBaseMessage(\n",
    "            role=m[\"role\"],\n",
    "            content=[KnowledgeBaseMessageTextContent(text=m[\"content\"])]\n",
    "        ) for m in messages if m[\"role\"] != \"system\"\n",
    "    ],\n",
    "    knowledge_source_params=[\n",
    "        SearchIndexKnowledgeSourceParams(\n",
    "            knowledge_source_name=knowledge_source_name,\n",
    "            include_references=True,\n",
    "            include_reference_source_data=True,\n",
    "            always_query_source=True\n",
    "        )\n",
    "    ],\n",
    "    include_activity=True,\n",
    "    retrieval_reasoning_effort=KnowledgeRetrievalLowReasoningEffort\n",
    ")\n",
    "\n",
    "result = agent_client.retrieve(retrieval_request=req)\n",
    "print(f\"‚úì Retrieved content from '{knowledge_base_name}' successfully.\\n\")\n",
    "\n",
    "print(f\"Query: {query_3.strip()}\")\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"AGENTIC RETRIEVAL RESPONSE:\\n\")\n",
    "\n",
    "response_parts = []\n",
    "for resp in result.response:\n",
    "    for content in resp.content:\n",
    "        response_parts.append(content.text)\n",
    "response_content = \"\\n\\n\".join(response_parts) if response_parts else \"No response\"\n",
    "print(response_content)\n",
    "\n",
    "# Show subqueries generated\n",
    "if result.activity:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"SUBQUERIES GENERATED:\\n\")\n",
    "    activity_data = [a.as_dict() for a in result.activity]\n",
    "    subquery_count = 0\n",
    "    for activity in activity_data:\n",
    "        if activity.get('type') == 'searchIndex':\n",
    "            subquery_count += 1\n",
    "            args = activity.get('search_index_arguments', {})\n",
    "            print(f\"{subquery_count}. {args.get('search', 'N/A')}\")\n",
    "            print(f\"   ‚Üí Found {activity.get('count', 0)} results\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ae54b7",
   "metadata": {},
   "source": [
    "---\n",
    "# COMPARISON: All 4 Search Approaches\n",
    "\n",
    "Let's compare the same query across all 4 methods:\n",
    "1. **Keyword Search** (BM25)\n",
    "2. **Vector Search** (Semantic Similarity)\n",
    "3. **Semantic Ranking** (L2 Reranking + Captions)\n",
    "4. **Agentic Retrieval** (LLM orchestration + Answer Synthesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27da6b6",
   "metadata": {},
   "source": [
    "## Comparison Query: \"Romantic luxury hotel with spa near water, parking included\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c688f201",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_query = \"romantic luxury hotel with spa near water, parking included\"\n",
    "\n",
    "print(f\"Query: '{comparison_query}'\")\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbabc4df",
   "metadata": {},
   "source": [
    "### Approach 1: Keyword Search (BM25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497bca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. KEYWORD SEARCH\n",
    "print(\"‚ùå KEYWORD SEARCH (BM25 - Word Matching):\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Use hotels-semantic-index for keyword search\n",
    "keyword_client = SearchClient(\n",
    "    endpoint=search_endpoint,\n",
    "    index_name=\"hotels-semantic-index\",\n",
    "    credential=credential\n",
    ")\n",
    "\n",
    "keyword_results = list(keyword_client.search(\n",
    "    search_text=comparison_query,\n",
    "    select=[\"HotelName\", \"Category\", \"Rating\"],\n",
    "    top=3\n",
    "))\n",
    "\n",
    "for i, result in enumerate(keyword_results, 1):\n",
    "    score = result.get(\"@search.score\", 0)\n",
    "    print(f\"{i}. {result['HotelName']} (BM25 Score: {score:.4f})\")\n",
    "    print(f\"   {result.get('Category', 'N/A')} | {result.get('Rating', 0)}‚òÖ\")\n",
    "    print(f\"   ‚ö†Ô∏è Just matches words - no understanding of 'romantic' or intent\")\n",
    "    print()\n",
    "\n",
    "print(f\"\\n{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d19706e",
   "metadata": {},
   "source": [
    "### Approach 2: Vector Search (Semantic Similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70a7683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. VECTOR SEARCH\n",
    "print(\"‚ö†Ô∏è VECTOR SEARCH (Semantic Similarity):\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "import requests\n",
    "\n",
    "# Get embedding for query\n",
    "def get_embedding(text):\n",
    "    token = credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token.token}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = {\"input\": text}\n",
    "    \n",
    "    for api_version in [\"2024-02-15-preview\", \"2024-02-01\", \"2023-05-15\"]:\n",
    "        try:\n",
    "            url = f\"{aoai_endpoint}/openai/deployments/{aoai_embedding_deployment}/embeddings?api-version={api_version}\"\n",
    "            response = requests.post(url, headers=headers, json=data, timeout=30)\n",
    "            if response.status_code == 200:\n",
    "                return response.json()[\"data\"][0][\"embedding\"]\n",
    "        except:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "query_vector = get_embedding(comparison_query)\n",
    "\n",
    "if query_vector:\n",
    "    vector_client = SearchClient(\n",
    "        endpoint=search_endpoint,\n",
    "        index_name=\"hotels-vector-index\",\n",
    "        credential=credential\n",
    "    )\n",
    "    \n",
    "    vector_results = list(vector_client.search(\n",
    "        vector_queries=[VectorizedQuery(vector=query_vector, k_nearest_neighbors=3, fields=\"DescriptionVector\")],\n",
    "        select=[\"HotelName\", \"Category\", \"Rating\"],\n",
    "        top=3\n",
    "    ))\n",
    "    \n",
    "    for i, result in enumerate(vector_results, 1):\n",
    "        score = result.get(\"@search.score\", 0)\n",
    "        print(f\"{i}. {result['HotelName']} (Similarity: {score:.4f})\")\n",
    "        print(f\"   {result.get('Category', 'N/A')} | {result.get('Rating', 0)}‚òÖ\")\n",
    "        print(f\"   ‚ö†Ô∏è Semantic match, but no explanation WHY\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"Could not generate embedding\")\n",
    "\n",
    "print(f\"\\n{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d63cb9c",
   "metadata": {},
   "source": [
    "### Approach 3: Semantic Ranking (L2 Reranking + Captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9990bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. SEMANTIC RANKING\n",
    "print(\"‚úÖ SEMANTIC RANKING (Reranking + Captions):\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "semantic_client = SearchClient(\n",
    "    endpoint=search_endpoint,\n",
    "    index_name=\"hotels-semantic-index\",\n",
    "    credential=credential\n",
    ")\n",
    "\n",
    "semantic_results = semantic_client.search(\n",
    "    query_type='semantic',\n",
    "    semantic_configuration_name='semantic-config',\n",
    "    search_text=comparison_query,\n",
    "    select=[\"HotelName\", \"Description\", \"Category\", \"Rating\"],\n",
    "    query_caption='extractive',\n",
    "    top=3\n",
    ")\n",
    "\n",
    "for i, result in enumerate(semantic_results, 1):\n",
    "    reranker_score = result.get(\"@search.reranker_score\", 0)\n",
    "    print(f\"{i}. {result['HotelName']} (Reranker Score: {reranker_score:.4f})\")\n",
    "    print(f\"   {result.get('Category', 'N/A')} | {result.get('Rating', 0)}‚òÖ\")\n",
    "    \n",
    "    captions = result.get(\"@search.captions\")\n",
    "    if captions:\n",
    "        caption = captions[0]\n",
    "        if hasattr(caption, 'highlights') and caption.highlights:\n",
    "            print(f\"   ‚úÖ Caption: {caption.highlights}\")\n",
    "        elif hasattr(caption, 'text'):\n",
    "            print(f\"   ‚úÖ Caption: {caption.text}\")\n",
    "    print()\n",
    "\n",
    "print(f\"\\n{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4458302",
   "metadata": {},
   "source": [
    "### Approach 4: Agentic Retrieval (LLM Orchestration + Answer Synthesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597d22a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. AGENTIC RETRIEVAL (using SDK)\n",
    "print(\"üöÄ AGENTIC RETRIEVAL (LLM Orchestration + Conversational Answer):\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": comparison_query}]\n",
    "\n",
    "agent_client = KnowledgeBaseRetrievalClient(\n",
    "    endpoint=search_endpoint, \n",
    "    knowledge_base_name=knowledge_base_name, \n",
    "    credential=credential\n",
    ")\n",
    "\n",
    "req = KnowledgeBaseRetrievalRequest(\n",
    "    messages=[\n",
    "        KnowledgeBaseMessage(\n",
    "            role=m[\"role\"],\n",
    "            content=[KnowledgeBaseMessageTextContent(text=m[\"content\"])]\n",
    "        ) for m in messages\n",
    "    ],\n",
    "    knowledge_source_params=[\n",
    "        SearchIndexKnowledgeSourceParams(\n",
    "            knowledge_source_name=knowledge_source_name,\n",
    "            include_references=True,\n",
    "            include_reference_source_data=True,\n",
    "            always_query_source=True\n",
    "        )\n",
    "    ],\n",
    "    include_activity=True,\n",
    "    retrieval_reasoning_effort=KnowledgeRetrievalLowReasoningEffort\n",
    ")\n",
    "\n",
    "result = agent_client.retrieve(retrieval_request=req)\n",
    "\n",
    "response_parts = []\n",
    "for resp in result.response:\n",
    "    for content in resp.content:\n",
    "        response_parts.append(content.text)\n",
    "response_content = \"\\n\\n\".join(response_parts) if response_parts else \"No response\"\n",
    "print(response_content)\n",
    "print()\n",
    "\n",
    "# Show how query was decomposed\n",
    "if result.activity:\n",
    "    print(\"\\nüß† Query Decomposition:\")\n",
    "    activity_data = [a.as_dict() for a in result.activity]\n",
    "    subquery_num = 0\n",
    "    for activity in activity_data:\n",
    "        if activity.get('type') == 'searchIndex':\n",
    "            subquery_num += 1\n",
    "            args = activity.get('search_index_arguments', {})\n",
    "            print(f\"   {subquery_num}. {args.get('search', 'N/A')}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f491dbfc",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary: Key Differences\n",
    "\n",
    "| Feature | Keyword | Vector | Semantic | Agentic |\n",
    "|---------|---------|--------|----------|----------|\n",
    "| **How it works** | Word matching (TF-IDF) | Embedding similarity | ML reranking | LLM orchestration |\n",
    "| **Query understanding** | ‚ùå None | ‚ö†Ô∏è Similarity only | ‚úÖ Context aware | ‚úÖ Intent analysis |\n",
    "| **Multi-part queries** | ‚ùå No decomposition | ‚ùå Single vector | ‚ùå Single query | ‚úÖ Auto-decomposed |\n",
    "| **Explanations** | ‚ùå Just scores | ‚ùå Just scores | ‚úÖ Captions | ‚úÖ Conversational |\n",
    "| **Answer format** | List of docs | List of docs | List + captions | Natural language |\n",
    "| **Citations** | ‚ùå No | ‚ùå No | ‚ö†Ô∏è Implicit | ‚úÖ [ref:X] |\n",
    "| **Conversational** | ‚ùå No context | ‚ùå No context | ‚ùå No context | ‚úÖ Multi-turn |\n",
    "| **Best for** | Exact terms | Concept match | Context + captions | Complex questions |\n",
    "\n",
    "## When to Use Each:\n",
    "\n",
    "**üîç Keyword Search:**\n",
    "- Fast, precise lookups\n",
    "- Known exact terms\n",
    "- Filters and facets\n",
    "\n",
    "**üéØ Vector Search:**\n",
    "- Semantic similarity\n",
    "- Multilingual search\n",
    "- Concept matching\n",
    "\n",
    "**‚ú® Semantic Ranking:**\n",
    "- Better relevance\n",
    "- Captions showing WHY\n",
    "- Question-answering\n",
    "\n",
    "**üöÄ Agentic Retrieval:**\n",
    "- Complex multi-part questions\n",
    "- Conversational AI\n",
    "- Natural language answers\n",
    "- Multi-turn dialogues\n",
    "\n",
    "## üí° Hybrid Approach (Best Practice):\n",
    "Combine all 4:\n",
    "- Vector search for semantic retrieval\n",
    "- Semantic ranking for better relevance\n",
    "- Agentic retrieval for conversational interface\n",
    "- Keyword filters for precise constraints"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
